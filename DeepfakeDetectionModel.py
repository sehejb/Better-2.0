# -*- coding: utf-8 -*-
"""Deepfake Base Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zQ355dqdmo1BPg2Z3V39RC8OWMqtXzHv
"""

import torch
from torch import nn
import torchvision.transforms as transforms
from torchvision import transforms, models
import cv2
import os
import random
from sklearn.model_selection import train_test_split
from pathlib import Path
import torch.nn.functional as F
import PIL

# Define paths
# [GOOGLE DRIVE PATHS REMOVED]
resnet50 = models.resnet50

"""## 1. Preprocess Data (Extract Frames)
Firstly, we aim to preprocess our data. The `output_path` here should be the same for both real and fake because we are labelling the title. A concern may be that the data will all be real first then fake. However, we will shuffle it later.
"""

def getFrames(file_path, output_path, type_frame):
    """
    Function to extract frames from video and save them in the output directory.
    """
    vid = cv2.VideoCapture(str(file_path))
    curr_frame = 0
    skip = 3  # only every 5th frame

    # If frames output folder not created, then create it
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    while True:
        success, frame = vid.read()
        if not success:
            break

        if curr_frame % skip == 0:
            filename = f"{type_frame}_frame_{curr_frame:05d}.jpg"
            cv2.imwrite(os.path.join(output_path, filename), frame)
        curr_frame += 1

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release resources
    vid.release()
    cv2.destroyAllWindows()


def getFramesFromFolder(folder_path, output_path, type_frame):
    """
    Function to extract frames from all video files in a folder.
    """
    for file in os.listdir(folder_path):
        getFrames(os.path.join(folder_path, file), output_path, type_frame)


"""### Sizing (More Preprocessing)

Now that we've gotten the frames, these frames need to be resized and augmented (optional) in order for our base model to be able to learn from it.

Let's define a transformation pipeline first for our frames.

The normalization values are based on the ImageNet dataset and will help us converge faster.
"""

transform = transforms.Compose([
    transforms.RandomCrop(196),
    transforms.RandomRotation(15),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(
        brightness=0.1,
        contrast=0.1,
        saturation=0.1,
        hue=0.05),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])

def get_image_paths(output_folder):
    """
    Collects and returns a shuffled list of image paths from the output folder.
    """
    image_paths = []
    for file in os.listdir(output_folder):
        file_path = os.path.join(output_folder, file)
        if os.path.isfile(file_path):
            image_paths.append(file_path)
    random.shuffle(image_paths)
    return image_paths


def prepare_data(image_paths):
    """
    Splits the image paths into training and testing sets and returns corresponding dataloaders.
    """
    train, test = train_test_split(image_paths, test_size=0.3)
    train_dataset = dataset(train, transform)
    test_dataset = dataset(test, transform)

    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)
    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, drop_last=True)

    return train_dataloader, test_dataloader


class dataset(torch.utils.data.Dataset):
    """
    Custom dataset for loading images with labels.
    """
    def __init__(self, image_paths, transform):
        self.image_paths = image_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, i):
        image = self.transform(PIL.Image.open(self.image_paths[i]))
        label = 1 if "real" in self.image_paths[i] else 0
        return image, label


"""## 2. Model
Here, we implement the `Resnet` model.
"""

class CustomCNN(nn.Module):
    """
    Custom CNN model using ResNet50 as the base.
    """
    def __init__(self):
        super().__init__()
        self.resnet = resnet50(pretrained=True)

        for param in self.resnet.parameters():
            param.requires_grad = True

        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = nn.Identity()
        self.dropout = nn.Dropout(p=0.2)
        self.fc1 = nn.Linear(1000, 128)
        self.fc2 = nn.Linear(128, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.resnet(x)
        x = self.dropout(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x


def train_model(model, train_dataloader, loss_fn, optimizer, epochs=3):
    """
    Function to train the model on the training dataset.
    """
    for epoch in range(epochs):
        model.train()
        for batch in train_dataloader:
            images, labels = batch
            optimizer.zero_grad()
            y_hat = model(images)
            train_loss = loss_fn(y_hat, labels)
            print(f"At epoch {epoch}, The training loss is: {train_loss}")
            train_loss.backward()
            optimizer.step()


def test_model(model, test_dataloader, loss_fn):
    """
    Function to evaluate the model on the test dataset.
    """
    model.eval()
    with torch.no_grad():
        for image, labels in test_dataloader:
            y_hat = model(image)
            test_loss = loss_fn(y_hat, labels)
            probabilities = F.softmax(y_hat, dim=1)
            predictions = torch.argmax(probabilities, dim=1)
            print("Test loss:", test_loss)
            print("Predictions:", predictions)
            print("Actual labels:", labels)


def save_model(model, filepath):
    """
    Function to save the trained model to a file.
    """
    torch.save(model.state_dict(), filepath)
    print(f"Model saved to {filepath}")


def load_model(model, filepath):
    """
    Function to load a trained model from a file.
    """
    model.load_state_dict(torch.load(filepath))
    model.eval()
    print(f"Model loaded from {filepath}")


if __name__ == "__main__":
    # Check if model already exists and load it
    model_path = "model.pth"
    if os.path.exists(model_path):
        model = CustomCNN()
        load_model(model, model_path)
    else:
        # Get image paths
        image_paths = get_image_paths("path")

        # Prepare train and test dataloaders
        train_dataloader, test_dataloader = prepare_data(image_paths)

        # Initialize model, loss function, and optimizer
        model = CustomCNN()
        loss_fn = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.005)
        # Train model if not loaded
        train_model(model, train_dataloader, loss_fn, optimizer, epochs=3)
        save_model(model, model_path)

    # Test model
    test_model(model, test_dataloader, loss_fn)
